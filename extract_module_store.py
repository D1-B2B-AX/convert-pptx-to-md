import os
import re
import json
from pptx import Presentation
from openai import OpenAI
from dotenv import load_dotenv
from utils.pptx_parser import (
    generate_doc_id, group_slides_into_courses, strip_code_fences
)

load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

SOURCE_DIR = './input'
OUTPUT_DIR = './output/module_store'


def generate_module_store_json(filename, course_idx, overview_text, curriculum_text):
    """GPT-4oì— JSON ìŠ¤í‚¤ë§ˆë¥¼ ì „ë‹¬í•˜ì—¬ ëª¨ë“ˆë³„ êµ¬ì¡°í™” ë°ì´í„°ë¥¼ ë°˜í™˜ë°›ìŠµë‹ˆë‹¤."""
    if len(curriculum_text) < 50:
        return None

    doc_id = generate_doc_id(filename, course_idx)

    prompt = f"""ë‹¹ì‹ ì€ B2B êµìœ¡ ì œì•ˆì„œì—ì„œ ì»¤ë¦¬í˜ëŸ¼ì„ ë¶„ì„í•˜ì—¬ ëª¨ë“ˆë³„ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[Input]
- File: {filename}
- Course Index: {course_idx}
- DOC_ID: {doc_id}
- Overview: {overview_text[:5000]}
- Curriculum: {curriculum_text[:25000]}

[Task]
ìœ„ Raw Textë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆì— ì •í™•íˆ ë§ëŠ” JSONì„ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

[Critical Rules]
1. ì—†ëŠ” ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤. ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” í•„ë“œëŠ” ë¹ˆ ë¬¸ìì—´("")ë¡œ ì ìœ¼ì‹­ì‹œì˜¤.
2. ê°•ì‚¬ ì•½ë ¥, íšŒì‚¬ í™ë³´, ë ˆí¼ëŸ°ìŠ¤(ìœ ì‚¬ ì‚¬ë¡€) ë“± ì»¤ë¦¬í˜ëŸ¼ê³¼ ë¬´ê´€í•œ ë‚´ìš©ì€ ì œê±°í•˜ì‹­ì‹œì˜¤.
3. ìœ íš¨í•œ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì˜¤ì§ {{"no_data": true}} ë¼ê³ ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. modules ë°°ì—´ì˜ ê° í•­ëª©ì€ ë°˜ë“œì‹œ íšŒì°¨(day)ì™€ ëª¨ë“ˆ ìˆœë²ˆ(module_index)ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
5. ì‹¤ìŠµì´ ì—†ëŠ” ëª¨ë“ˆì€ practicesë¥¼ ë¹ˆ ë°°ì—´([])ë¡œ ì ìœ¼ì‹­ì‹œì˜¤.

[JSON Schema]
{{
  "course_name": "ê³¼ì •ëª…",
  "client": "ê³ ê°ì‚¬ëª… (íŒŒì¼ëª…ì´ë‚˜ ë³¸ë¬¸ì—ì„œ ì¶”ì¶œ)",
  "industry": "ì‚°ì—…êµ° (ê¸ˆìœµ/ì œì¡°/IT/í†µì‹ /ìœ í†µ/ê³µê³µ/ê¸°íƒ€)",
  "topic": "êµìœ¡ ì£¼ì œ í•µì‹¬ í‚¤ì›Œë“œ",
  "target": "êµìœ¡ ëŒ€ìƒì",
  "level": "ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰/ì „ ìˆ˜ì¤€",
  "total_duration": "ì´ êµìœ¡ ì‹œìˆ˜ (ì˜ˆ: 21H)",
  "total_days": 3,
  "tools": "ì‚¬ìš©ë˜ëŠ” AI ë„êµ¬/ê¸°ìˆ  (ì‰¼í‘œ êµ¬ë¶„)",
  "format": "êµìœ¡ ë°©ì‹ (ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸/ë¸”ë Œë””ë“œ)",
  "overview_summary": "êµìœ¡ì˜ ë°°ê²½, ëª©ì , í•™ìŠµ ëª©í‘œë¥¼ 2~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
  "roadmap": "ê³¼ì • ì „ì²´ íë¦„ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ (ì˜ˆ: 1ì¼ì°¨ ê¸°ì´ˆ â†’ 2ì¼ì°¨ ì‘ìš© â†’ 3ì¼ì°¨ ì‹¤ì „ í”„ë¡œì íŠ¸)",
  "modules": [
    {{
      "day": 1,
      "module_index": 1,
      "module_name": "ëª¨ë“ˆëª…",
      "module_summary": "ì´ ëª¨ë“ˆì´ ë¬´ì—‡ì„ ë‹¤ë£¨ëŠ”ì§€ 1ì¤„ ìš”ì•½",
      "duration": "2H",
      "tools": "ì´ ëª¨ë“ˆì—ì„œ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)",
      "objectives": ["í•™ìŠµëª©í‘œ1", "í•™ìŠµëª©í‘œ2"],
      "details": ["í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸1", "í•µì‹¬ í•™ìŠµ í¬ì¸íŠ¸2"],
      "practices": ["ì‹¤ìŠµ í™œë™1"]
    }}
  ]
}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0
        )
        result = response.choices[0].message.content.strip()
        parsed = json.loads(result)

        if parsed.get("no_data"):
            return None
        if not parsed.get("modules"):
            return None

        return parsed

    except Exception as e:
        print(f"  âŒ LLM Error: {e}")
        return None


def save_module_store(filename, course_idx, doc_id, parsed):
    """ëª¨ë“ˆë³„ ê°œë³„ íŒŒì¼ + course_overview.md + metadata JSONì„ ì €ì¥í•©ë‹ˆë‹¤."""
    safe_id = re.sub(r'[^a-zA-Z0-9ê°€-í£_]', '_', doc_id.replace('CURR::', ''))
    course_dir = os.path.join(OUTPUT_DIR, safe_id)
    metadata_dir = os.path.join(course_dir, 'metadata')
    os.makedirs(metadata_dir, exist_ok=True)

    course_name = parsed.get('course_name', 'ì •ë³´ ì—†ìŒ')
    client_name = parsed.get('client', 'ì •ë³´ ì—†ìŒ')
    industry = parsed.get('industry', 'ê¸°íƒ€')
    topic = parsed.get('topic', '')
    target = parsed.get('target', '')
    level = parsed.get('level', '')
    total_duration = parsed.get('total_duration', '')
    total_days = parsed.get('total_days', 0)
    tools = parsed.get('tools', '')
    fmt = parsed.get('format', '')
    overview_summary = parsed.get('overview_summary', '')
    roadmap = parsed.get('roadmap', '')

    # --- course_overview.md ---
    overview_lines = [
        f"# {client_name}: {course_name}",
        f"DOC_ID: {doc_id}",
        f"CLIENT: {client_name}",
        f"INDUSTRY: {industry}",
        f"TOPIC: {topic}",
        f"TARGET: {target}",
        f"LEVEL: {level}",
        f"DURATION: {total_duration} ({total_days}ì¼)",
        f"TOOLS: {tools}",
        f"FORMAT: {fmt}",
        f"SOURCE_FILE: {filename}",
        "",
        "## êµìœ¡ ê°œìš”",
        overview_summary,
        "",
        "## ë¡œë“œë§µ",
        roadmap,
        "",
        "## ëª¨ë“ˆ ëª©ë¡",
    ]

    for mod in parsed.get('modules', []):
        day = mod.get('day', 0)
        mi = mod.get('module_index', 0)
        name = mod.get('module_name', '')
        dur = mod.get('duration', '')
        overview_lines.append(f"- {day}ì¼ì°¨ M{mi:02d}: {name} ({dur})")

    overview_path = os.path.join(course_dir, 'course_overview.md')
    with open(overview_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(overview_lines))
    print(f"    âœ… {os.path.basename(overview_path)}")

    # --- course_overview metadata ---
    overview_meta = {
        "doc_id": doc_id,
        "doc_type": "course_overview",
        "course_name": course_name,
        "client": client_name,
        "industry": industry,
        "topic": topic,
        "target": target,
        "level": level,
        "total_duration": total_duration,
        "total_days": total_days,
        "tools": tools,
        "format": fmt,
        "source_file": filename,
    }
    meta_path = os.path.join(metadata_dir, 'course_overview.json')
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(overview_meta, f, ensure_ascii=False, indent=2)

    # --- ëª¨ë“ˆë³„ íŒŒì¼ ---
    for mod in parsed.get('modules', []):
        day = mod.get('day', 0)
        mi = mod.get('module_index', 0)
        module_name = mod.get('module_name', 'unknown')
        module_summary = mod.get('module_summary', '')
        duration = mod.get('duration', '')
        mod_tools = mod.get('tools', '')
        objectives = mod.get('objectives', [])
        details = mod.get('details', [])
        practices = mod.get('practices', [])

        # íŒŒì¼ëª… ìƒì„±: d{NN}_m{NN}_{name}.md
        safe_name = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '_', module_name)
        safe_name = re.sub(r'_+', '_', safe_name).strip('_').lower()
        md_filename = f"d{day:02d}_m{mi:02d}_{safe_name}.md"

        # ëª¨ë“ˆ ë‚´ìš©
        lines = [
            f"# {client_name}: {course_name}",
            f"{day}ì¼ì°¨ | {total_duration} | {industry} | {level}",
            "",
            f"## {module_name}",
            f"MODULE_SUMMARY: {module_summary}",
            f"DURATION: {duration}",
            f"TOOLS: {mod_tools if mod_tools else '-'}",
            "",
        ]

        if objectives:
            lines.append("### í•™ìŠµëª©í‘œ")
            for obj in objectives:
                lines.append(f"- {obj}")
            lines.append("")

        if details:
            lines.append("### ì„¸ë¶€ë‚´ìš©")
            for det in details:
                lines.append(f"- {det}")
            lines.append("")

        if practices:
            lines.append("### ì‹¤ìŠµ")
            for prac in practices:
                lines.append(f"- {prac}")
            lines.append("")

        mod_path = os.path.join(course_dir, md_filename)
        with open(mod_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        print(f"    âœ… {md_filename}")

        # ëª¨ë“ˆ metadata
        mod_meta = {
            "doc_id": f"{doc_id}::m{mi:02d}",
            "doc_type": "module",
            "course_name": course_name,
            "client": client_name,
            "industry": industry,
            "module_name": module_name,
            "module_summary": module_summary,
            "day": day,
            "module_index": mi,
            "duration": duration,
            "tools": mod_tools,
            "level": level,
            "source_file": filename,
        }
        meta_key = f"d{day:02d}_m{mi:02d}"
        mod_meta_path = os.path.join(metadata_dir, f"{meta_key}.json")
        with open(mod_meta_path, 'w', encoding='utf-8') as f:
            json.dump(mod_meta, f, ensure_ascii=False, indent=2)

    return len(parsed.get('modules', []))


def process_module_store(source_dir=None):
    """ëª¨ë“ˆ ìŠ¤í† ì–´ ë©”ì¸ íŒŒì´í”„ë¼ì¸."""
    src = source_dir or SOURCE_DIR
    if not os.path.exists(src):
        print(f"âŒ ì›ë³¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {src}")
        return

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    files = [f for f in os.listdir(src) if f.endswith('.pptx')]
    print(f"ğŸš€ ì´ {len(files)}ê°œì˜ ì œì•ˆì„œ -> [ëª¨ë“ˆ ìŠ¤í† ì–´] ë³€í™˜ ì‹œì‘...\n")

    for file in files:
        file_path = os.path.join(src, file)
        print(f"ğŸ“„ ë¶„ì„ ì¤‘: {file}")

        try:
            prs = Presentation(file_path)
            courses = group_slides_into_courses(prs)
            print(f"  â””â”€ ì ì¬ ê³¼ì • ìˆ˜: {len(courses)}ê°œ")

            for idx, course in enumerate(courses):
                full_overview = "\n\n".join(course['overview'])
                full_curriculum = "\n\n".join(course['curriculum'])
                doc_id = generate_doc_id(file, idx + 1)

                parsed = generate_module_store_json(
                    file, idx + 1, full_overview, full_curriculum
                )

                if parsed:
                    count = save_module_store(file, idx + 1, doc_id, parsed)
                    print(f"    ğŸ“¦ ê³¼ì • {idx+1}: {count}ê°œ ëª¨ë“ˆ ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"    ğŸš« [Drop] ê³¼ì • {idx+1}: ì •ë³´ ë¶€ì¡±")

        except Exception as e:
            print(f"  âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {file} -> {e}")

    print(f"\nğŸ‰ [ëª¨ë“ˆ ìŠ¤í† ì–´] ë³€í™˜ ì™„ë£Œ! '{OUTPUT_DIR}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    process_module_store()
