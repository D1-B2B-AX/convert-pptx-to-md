import os
import re
import json 
import pandas as pd
from pptx import Presentation
from openai import OpenAI
from dotenv import load_dotenv
from utils.pptx_parser import normalize, is_slide_hidden, get_visual_title, extract_text_from_slide

# =========================================================
# [ì„¤ì •] API í‚¤ ë° ê²½ë¡œ
# =========================================================
load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

SOURCE_DIR = './input'
OUTPUT_DIR = './output/curriculum/'

# =========================================================
# [í‚¤ì›Œë“œ ì„¤ì •]
# =========================================================
EXCLUDE_KEYWORDS = [
    "ìœ ì‚¬", "ì‚¬ë¡€", "ì‹¤ì ", "reference", "case", "history", "result",
    "ê°•ì‚¬í”„ë¡œí•„", "ìˆ˜í–‰ì‹¤ì ", "ì œì•ˆì‚¬", "íšŒì‚¬ì†Œê°œ"
]

OVERVIEW_KEYWORDS = [
    "ê³¼ì • ì†Œê°œ", "ê³¼ì •ì†Œê°œ", "ê³¼ì • ê°œìš”", "ê³¼ì •ê°œìš”", 
    "êµìœ¡ ì†Œê°œ", "êµìœ¡ì†Œê°œ", "êµìœ¡ ê°œìš”", "êµìœ¡ê°œìš”", 
    "ê°œìš”", "ì†Œê°œ", "overview", "summary", "ìš”ì•½", "ì œì•ˆ ë°°ê²½", "ê¸°íš ì˜ë„",
    "ëª©í‘œ", "ëŒ€ìƒ" 
]

CURRICULUM_KEYWORDS = [
    "ì»¤ë¦¬í˜ëŸ¼", "ì„¸ë¶€ê³¼ì •", "êµìœ¡ê³¼ì •", "êµìœ¡ë‚´ìš©", "ëª¨ë“ˆêµ¬ì„±", 
    "ìƒì„¸ê³¼ì •", "í”„ë¡œê·¸ë¨", "module", "schedule", "curriculum",
    "ëª¨ë“ˆ", "êµ¬ì„±", "ì¼ì •", "ë°©ë²•", "contents", "agenda", "syllabus",
    "1ì¼ì°¨", "2ì¼ì°¨", "1h", "2h", "time" 
]

# =========================================================
# [ê¸°ëŠ¥ 1] PPTX íŒŒì‹± í—¬í¼ í•¨ìˆ˜ë“¤
# =========================================================
def normalize(text):
    return re.sub(r'\s+', '', str(text).lower())

def get_visual_title(slide):
    if slide.shapes.title and slide.shapes.title.text.strip():
        return slide.shapes.title.text.strip()
    
    candidates = []
    for shape in slide.shapes:
        if not hasattr(shape, "text") or not shape.text.strip():
            continue
        # ìƒë‹¨ì— ìœ„ì¹˜í•œ í…ìŠ¤íŠ¸ë¥¼ ì œëª© í›„ë³´ë¡œ ê°„ì£¼
        if shape.top < 2000000: 
            candidates.append((shape.top, shape.left, shape.text.strip()))
    
    if candidates:
        candidates.sort(key=lambda x: (x[0], x[1])) 
        return candidates[0][2]
    return ""

def check_table_headers(slide):
    for shape in slide.shapes:
        if shape.has_table:
            header_text = ""
            try:
                for cell in shape.table.rows[0].cells:
                    header_text += cell.text + " "
            except:
                continue
            norm_header = normalize(header_text)
            for key in CURRICULUM_KEYWORDS:
                if normalize(key) in norm_header:
                    return True
    return False

def classify_slide_advanced(slide):
    title = get_visual_title(slide)
    norm_title = normalize(title)
    
    for key in EXCLUDE_KEYWORDS:
        if normalize(key) in norm_title: return "EXCLUDE"
    for key in CURRICULUM_KEYWORDS:
        if normalize(key) in norm_title: return "CURRICULUM"
    for key in OVERVIEW_KEYWORDS:
        if normalize(key) in norm_title: return "OVERVIEW"
    if check_table_headers(slide):
        return "CURRICULUM"
    return "OTHER"

def extract_text_from_slide(slide):
    lines = []
    visual_title = get_visual_title(slide)
    if visual_title:
        lines.append(f"### {visual_title}")
    
    for shape in slide.shapes:
        if hasattr(shape, "text") and shape.text.strip():
            if shape.text.strip() == visual_title:
                continue
            lines.append(shape.text.strip())
        
        if shape.has_table:
            for row in shape.table.rows:
                # í‘œ ë‚´ìš© í•œ ì¤„ë¡œ í•©ì¹˜ê¸° (Markdown ë³€í™˜ ì‹œ LLMì´ ì²˜ë¦¬í•˜ë„ë¡ ì›ë³¸ ìœ ì§€)
                row_cells = [c.text.replace('\n', ' ').strip() for c in row.cells if c.text.strip()]
                if row_cells:
                    lines.append(f"| {' | '.join(row_cells)} |")
    return "\n".join(lines)

# =========================================================
# [ê¸°ëŠ¥ 2] LLMì„ ì´ìš©í•œ Markdown ë³€í™˜
# =========================================================
def generate_rag_markdown(filename, course_idx, overview_text, curriculum_text):
    # ë‚´ìš©ì´ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
    if len(curriculum_text) < 50: 
        return None

    # ìš”ì²­í•˜ì‹  Metadata Blockì´ í¬í•¨ëœ í”„ë¡¬í”„íŠ¸
    prompt = f"""
    ë‹¹ì‹ ì€ 'B2B êµìœ¡ ì»¤ë¦¬í˜ëŸ¼ ì •ë¦¬ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
    ì•„ë˜ ì œê³µëœ Raw Textë¥¼ ë¶„ì„í•˜ì—¬, RAG ê²€ìƒ‰ì— ìµœì í™”ëœ **Clean Markdown** í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ì‹­ì‹œì˜¤.

    [Input Source]
    - File: {filename}
    - Context: {overview_text[:3000]}
    - Content: {curriculum_text[:15000]}

    [Output Format Rules - Strict Markdown]
    1. **Metadata Block**: ë¬¸ì„œ ìµœìƒë‹¨ì— ì•„ë˜ ì–‘ì‹ì„ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ.
       > **File**: {filename}
    
    2. **Section Structuring**:
       - ê³¼ì •ëª…/ì£¼ì œëŠ” `# (H1)` íƒœê·¸ ì‚¬ìš©
       - 'êµìœ¡ ê°œìš”', 'í•™ìŠµ ëª©í‘œ' ë“± ëŒ€ë¶„ë¥˜ëŠ” `## (H2)` íƒœê·¸ ì‚¬ìš©
       - ì„¸ë¶€ ëª¨ë“ˆ/ì‹œê°„í‘œëŠ” `### (H3)` íƒœê·¸ ì‚¬ìš©
    
    3. **Curriculum Table**:
       - ì»¤ë¦¬í˜ëŸ¼ ìƒì„¸ ë‚´ìš©ì€ ë°˜ë“œì‹œ Markdown Table í˜¹ì€ ê³„ì¸µí˜• List(`-`)ë¡œ ì •ë¦¬í•  ê²ƒ.
       - ì‹œê°„(Time), ëª¨ë“ˆëª…(Module), ì„¸ë¶€ë‚´ìš©(Detail)ì´ ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ì•¼ í•¨.

    4. **Filtering**:
       - 'ê°•ì‚¬ ì•½ë ¥', 'íšŒì‚¬ í™ë³´', 'ë ˆí¼ëŸ°ìŠ¤' ë“± ì»¤ë¦¬í˜ëŸ¼ê³¼ ë¬´ê´€í•œ ë‚´ìš©ì€ ê³¼ê°íˆ ì‚­ì œí•  ê²ƒ.
       - ì •ë³´ê°€ ì—†ìœ¼ë©´ ì—†ëŠ” ëŒ€ë¡œ ë†”ë‘˜ ê²ƒ (ì§€ì–´ë‚´ì§€ ë§ ê²ƒ).
       
    5. **No Chit-chat**: ì„œë¡ /ë³¸ë¡  ì—†ì´ ì˜¤ì§ Markdown ë‚´ìš©ë§Œ ì¶œë ¥í•  ê²ƒ. ë§Œì•½ ìœ íš¨í•œ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ê°€ ì—†ë‹¤ë©´ ì˜¤ì§ `NO_DATA`ë¼ê³ ë§Œ ì¶œë ¥.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        result = response.choices[0].message.content.strip()
        
        if "NO_DATA" in result: return None
        if len(result) < 50: return None
        
        return result

    except Exception as e:
        print(f"  âŒ LLM Error: {e}")
        return None

# =========================================================
# [ê¸°ëŠ¥ 3] ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
# =========================================================
def process_rag_data_final():
    if not os.path.exists(SOURCE_DIR):
        print(f"âŒ ì›ë³¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SOURCE_DIR}")
        return

    # í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„± (output/curriculum)
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    files = [f for f in os.listdir(SOURCE_DIR) if f.endswith('.pptx')]
    print(f"ğŸš€ ì´ {len(files)}ê°œì˜ ì œì•ˆì„œ -> [ì»¤ë¦¬í˜ëŸ¼] Markdown ë³€í™˜ ì‹œì‘...\n")

    for file in files:
        file_path = os.path.join(SOURCE_DIR, file)
        print(f"ğŸ“„ ë¶„ì„ ì¤‘: {file}")

        try:
            prs = Presentation(file_path)
            courses = [] 
            current_course = {'overview': [], 'curriculum': []}

            # ---------------------------------------------------------
            # [í•µì‹¬] PPTX íŒŒì‹± ëª¨ë“ˆì„ í™œìš©í•œ ê¹”ë”í•œ ë°˜ë³µë¬¸
            # ---------------------------------------------------------
            for i, slide in enumerate(prs.slides):
                
                # 1. ìˆ¨ê¸°ê¸° ì²˜ë¦¬ëœ ìŠ¬ë¼ì´ë“œ í†µê³¼
                if is_slide_hidden(slide):
                    continue

                # 2. ì»¤ë¦¬í˜ëŸ¼ ì¶”ì¶œìš© ìŠ¬ë¼ì´ë“œ ë¶„ë¥˜
                slide_type = classify_slide_advanced(slide)
                if slide_type == "EXCLUDE": 
                    continue

                # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ
                text = extract_text_from_slide(slide)

                # 4. ê°œìš”/ì»¤ë¦¬í˜ëŸ¼ ë¬¶ê¸° ë¡œì§
                if slide_type == "OVERVIEW":
                    if current_course['curriculum']: 
                        courses.append(current_course)
                        current_course = {'overview': [], 'curriculum': []}
                    current_course['overview'].append(text)

                elif slide_type == "CURRICULUM":
                    current_course['curriculum'].append(text)

            if current_course['curriculum']:
                courses.append(current_course)

            print(f"  â””â”€ ì ì¬ ê³¼ì • ìˆ˜: {len(courses)}ê°œ")
            
            # ---------------------------------------------------------
            # LLM ë³€í™˜ ë° íŒŒì¼ ì €ì¥
            # ---------------------------------------------------------
            for idx, course in enumerate(courses):
                full_overview = "\n\n".join(course['overview'])
                full_curriculum = "\n\n".join(course['curriculum'])
                
                md_content = generate_rag_markdown(file, idx+1, full_overview, full_curriculum)
                
                if md_content:
                    base_name = os.path.splitext(file)[0]
                    safe_name = re.sub(r'[^a-zA-Z0-9ê°€-í£]', '_', base_name)
                    
                    md_filename = f"{safe_name}_Course_{idx+1}.md"
                    save_path = os.path.join(OUTPUT_DIR, md_filename)
                    
                    with open(save_path, 'w', encoding='utf-8') as f:
                        f.write(md_content)
                    
                    print(f"    âœ… Markdown ì €ì¥ ì™„ë£Œ: {md_filename}")
                else:
                    print(f"    ğŸš« [Drop] ê³¼ì • {idx+1}: ì •ë³´ ë¶€ì¡±")

        except Exception as e:
            print(f"  âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {file} -> {e}")

    print(f"\nğŸ‰ [ì»¤ë¦¬í˜ëŸ¼] Markdown ë³€í™˜ ì™„ë£Œ! '{OUTPUT_DIR}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    process_rag_data_final()