import os
import re
import json
from pptx import Presentation
from openai import OpenAI
from dotenv import load_dotenv
from utils.pptx_parser import (
    generate_doc_id, group_slides_into_courses, strip_code_fences
)

load_dotenv()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

SOURCE_DIR = './input'
OUTPUT_DIR = './output/curriculum_store'


def generate_curriculum_store_markdown(filename, course_idx, overview_text, curriculum_text):
    """GPT-4oë¡œ í…Œì´ë¸” í¬ë§· ë³´ì¡´ Markdownì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if len(curriculum_text) < 50:
        return None, None

    doc_id = generate_doc_id(filename, course_idx)

    prompt = f"""ë‹¹ì‹ ì€ B2B êµìœ¡ ì œì•ˆì„œì—ì„œ ì»¤ë¦¬í˜ëŸ¼ì„ ì¶”ì¶œí•˜ì—¬ RAG ê²€ìƒ‰ì— ìµœì í™”ëœ Markdownìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[Input]
- File: {filename}
- Course Index: {course_idx}
- DOC_ID: {doc_id}
- Overview: {overview_text[:5000]}
- Curriculum: {curriculum_text[:25000]}

[Task]
ìœ„ Raw Textë¥¼ ë¶„ì„í•˜ì—¬ ì•„ë˜ í¬ë§·ì— ì •í™•íˆ ë§ëŠ” Markdownì„ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

[Critical Rules]
1. ì ˆëŒ€ë¡œ ```markdown ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ì§€ ë§ˆì‹­ì‹œì˜¤. ìˆœìˆ˜ Markdown í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
2. ì—†ëŠ” ì •ë³´ë¥¼ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤. ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” í•„ë“œëŠ” "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ ì ìœ¼ì‹­ì‹œì˜¤.
3. ê°•ì‚¬ ì•½ë ¥, íšŒì‚¬ í™ë³´, ë ˆí¼ëŸ°ìŠ¤(ìœ ì‚¬ ì‚¬ë¡€) ë“± ì»¤ë¦¬í˜ëŸ¼ê³¼ ë¬´ê´€í•œ ë‚´ìš©ì€ ì œê±°í•˜ì‹­ì‹œì˜¤.
4. ìœ íš¨í•œ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì˜¤ì§ NO_DATA ë¼ê³ ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
5. **ê°€ì¥ ì¤‘ìš”: ì»¤ë¦¬í˜ëŸ¼ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ì‹­ì‹œì˜¤. ëª¨ë“ˆë³„ ê°œì¡°ì‹ bullet listë¡œ ë³€í™˜í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.**
6. ì›ë³¸ì— Markdown í…Œì´ë¸”(| | |)ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ì›ë³¸ì´ í‘œ í˜•íƒœê°€ ì•„ë‹ˆë”ë¼ë„ ì‹œìˆ˜/ëª¨ë“ˆ/ë‚´ìš©ì´ êµ¬ì¡°í™”ë˜ì–´ ìˆìœ¼ë©´ Markdown í…Œì´ë¸”ë¡œ ì •ë¦¬í•˜ì‹­ì‹œì˜¤.

[Output Format - ë°˜ë“œì‹œ ì´ êµ¬ì¡°ë¥¼ ë”°ë¥´ì‹­ì‹œì˜¤]

# [COURSE] {{ê³¼ì •ëª…}}
DOC_ID: {doc_id}
CLIENT: {{ê³ ê°ì‚¬ëª… - íŒŒì¼ëª…ì´ë‚˜ ë³¸ë¬¸ì—ì„œ ì¶”ì¶œ}}
INDUSTRY: {{ì‚°ì—…êµ° - ê¸ˆìœµ/ì œì¡°/IT/í†µì‹ /ìœ í†µ/ê³µê³µ/ê¸°íƒ€}}
TOPIC: {{êµìœ¡ ì£¼ì œ í•µì‹¬ í‚¤ì›Œë“œ}}
TARGET: {{êµìœ¡ ëŒ€ìƒì}}
LEVEL: {{ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰/ì „ ìˆ˜ì¤€ - ë³¸ë¬¸ì—ì„œ ì¶”ë¡ }}
DURATION: {{ì´ êµìœ¡ ì‹œìˆ˜, ì˜ˆ: 21H (3ì¼)}}
TOOLS: {{ì‚¬ìš©ë˜ëŠ” AI ë„êµ¬/ê¸°ìˆ  - ì‰¼í‘œ êµ¬ë¶„}}
FORMAT: {{êµìœ¡ ë°©ì‹ - ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸/ë¸”ë Œë””ë“œ}}
SOURCE_FILE: {filename}

## êµìœ¡ ê°œìš”
{{êµìœ¡ì˜ ë°°ê²½, ëª©ì , í•™ìŠµ ëª©í‘œë¥¼ 2~4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½}}

## ì»¤ë¦¬í˜ëŸ¼

{{ì»¤ë¦¬í˜ëŸ¼ í…Œì´ë¸”ì„ ì›ë³¸ êµ¬ì¡° ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ì—¬ ì¶œë ¥. ì•„ë˜ëŠ” ì˜ˆì‹œ í˜•íƒœ:}}

| íšŒì°¨ | ëª¨ë“ˆ | ì‹œìˆ˜ | ì£¼ìš” ë‚´ìš© |
|------|------|------|-----------|
| 1ì¼ì°¨ | ëª¨ë“ˆëª… | 2H | í•µì‹¬ í•™ìŠµ ë‚´ìš© ìš”ì•½ |

{{íšŒì°¨ê°€ ì—¬ëŸ¬ ê°œì´ë©´ íšŒì°¨ë³„ë¡œ í…Œì´ë¸”ì„ ë¶„ë¦¬í•˜ê±°ë‚˜, í•˜ë‚˜ì˜ í…Œì´ë¸”ì— íšŒì°¨ ì»¬ëŸ¼ìœ¼ë¡œ êµ¬ë¶„}}

## DAY_FLOW
{{ê° íšŒì°¨ë³„ í•™ìŠµ íë¦„ì„ 1ì¤„ë¡œ ìš”ì•½. ì˜ˆ:}}
- 1ì¼ì°¨: ê¸°ì´ˆ ê°œë… ì´í•´ â†’ ë„êµ¬ ì‹¤ìŠµ
- 2ì¼ì°¨: ì‹¬í™” ì‘ìš© â†’ íŒ€ í”„ë¡œì íŠ¸
- 3ì¼ì°¨: ì‹¤ì „ í”„ë¡œì íŠ¸ â†’ ë°œí‘œ ë° í”¼ë“œë°±

## PROGRESSION
{{ê³¼ì • ì „ì²´ì˜ ë‚œì´ë„ íë¦„ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…. ì˜ˆ: "ê¸°ì´ˆ ê°œë…ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì‹¤ì „ í”„ë¡œì íŠ¸ê¹Œì§€ ì§„í–‰í•˜ëŠ” ìƒí–¥ì‹ êµ¬ì¡°"}}

## DESIGN_RATIONALE
{{ì´ ì»¤ë¦¬í˜ëŸ¼ì´ ì™œ ì´ë ‡ê²Œ ì„¤ê³„ë˜ì—ˆëŠ”ì§€, êµìœ¡ ì„¤ê³„ ì˜ë„ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…. ì˜ˆ: "LLM ê¸°ì´ˆë¥¼ ë¨¼ì € ë‹¤ë£¨ì–´ ì „ì‚¬ ê³µí†µ ì—­ëŸ‰ì„ í™•ë³´í•œ ë’¤, ë¶€ì„œë³„ ë§ì¶¤ ì‹¤ìŠµìœ¼ë¡œ ì¦‰ì‹œ ì—…ë¬´ ì ìš©ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„"}}
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        result = response.choices[0].message.content.strip()

        if "NO_DATA" in result:
            return None, None
        if len(result) < 50:
            return None, None

        result = strip_code_fences(result)

        # metadata ì¶”ì¶œ (í—¤ë” í•„ë“œì—ì„œ íŒŒì‹±)
        metadata = {
            "doc_id": doc_id,
            "doc_type": "curriculum",
            "source_file": filename,
            "course_index": course_idx,
        }
        field_patterns = {
            "course_name": r'^# \[COURSE\] (.+)$',
            "client": r'^CLIENT: (.+)$',
            "industry": r'^INDUSTRY: (.+)$',
            "topic": r'^TOPIC: (.+)$',
            "target": r'^TARGET: (.+)$',
            "level": r'^LEVEL: (.+)$',
            "duration": r'^DURATION: (.+)$',
            "tools": r'^TOOLS: (.+)$',
            "format": r'^FORMAT: (.+)$',
        }
        for key, pattern in field_patterns.items():
            match = re.search(pattern, result, re.MULTILINE)
            if match:
                metadata[key] = match.group(1).strip()

        return result, metadata

    except Exception as e:
        print(f"  âŒ LLM Error: {e}")
        return None, None


def save_curriculum_store(filename, course_idx, md_content, metadata):
    """curriculum.md + metadata.jsonì„ ì €ì¥í•©ë‹ˆë‹¤."""
    doc_id = metadata.get('doc_id', generate_doc_id(filename, course_idx))
    safe_id = re.sub(r'[^a-zA-Z0-9ê°€-í£_]', '_', doc_id.replace('CURR::', ''))
    course_dir = os.path.join(OUTPUT_DIR, safe_id)
    os.makedirs(course_dir, exist_ok=True)

    md_path = os.path.join(course_dir, 'curriculum.md')
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

    meta_path = os.path.join(course_dir, 'metadata.json')
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    print(f"    âœ… curriculum.md + metadata.json ì €ì¥ ì™„ë£Œ ({safe_id}/)")


def process_curriculum_store(source_dir=None):
    """ì»¤ë¦¬í˜ëŸ¼ ìŠ¤í† ì–´ ë©”ì¸ íŒŒì´í”„ë¼ì¸."""
    src = source_dir or SOURCE_DIR
    if not os.path.exists(src):
        print(f"âŒ ì›ë³¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {src}")
        return

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    files = [f for f in os.listdir(src) if f.endswith('.pptx')]
    print(f"ğŸš€ ì´ {len(files)}ê°œì˜ ì œì•ˆì„œ -> [ì»¤ë¦¬í˜ëŸ¼ ìŠ¤í† ì–´] ë³€í™˜ ì‹œì‘...\n")

    for file in files:
        file_path = os.path.join(src, file)
        print(f"ğŸ“„ ë¶„ì„ ì¤‘: {file}")

        try:
            prs = Presentation(file_path)
            courses = group_slides_into_courses(prs)
            print(f"  â””â”€ ì ì¬ ê³¼ì • ìˆ˜: {len(courses)}ê°œ")

            for idx, course in enumerate(courses):
                full_overview = "\n\n".join(course['overview'])
                full_curriculum = "\n\n".join(course['curriculum'])

                md_content, metadata = generate_curriculum_store_markdown(
                    file, idx + 1, full_overview, full_curriculum
                )

                if md_content and metadata:
                    save_curriculum_store(file, idx + 1, md_content, metadata)
                else:
                    print(f"    ğŸš« [Drop] ê³¼ì • {idx+1}: ì •ë³´ ë¶€ì¡±")

        except Exception as e:
            print(f"  âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {file} -> {e}")

    print(f"\nğŸ‰ [ì»¤ë¦¬í˜ëŸ¼ ìŠ¤í† ì–´] ë³€í™˜ ì™„ë£Œ! '{OUTPUT_DIR}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    process_curriculum_store()
